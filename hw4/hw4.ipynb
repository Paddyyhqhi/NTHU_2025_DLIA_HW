{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "609dcb62-c2f8-4c6d-9c89-63dc0148a87c"
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "### Lab 4\n",
    "\n",
    "# National Tsing Hua University\n",
    "\n",
    "#### Spring 2025\n",
    "\n",
    "#### 11320IEEM 513600\n",
    "\n",
    "#### Deep Learning and Industrial Applications\n",
    "    \n",
    "## Lab 4: Predicting Stock Price with Deep Learning\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "061c22d2-eec4-40f4-866b-ccaa2d9a2963",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Introduction\n",
    "\n",
    "In this lab, we explore the application of time-series datasets using Long Short-Term Memory (LSTM) networks, a type of recurrent neural network, to predict stock prices. Specifically, we will use historical price data from Nvidia to forecast the stock's price for the next day based on the prices of the previous N days. This approach is particularly relevant given the volatile nature of stock markets and the increasing reliance on automated trading systems.\n",
    "\n",
    "### Objectives\n",
    "\n",
    "- To understand the fundamentals of LSTM networks and their application in time-series forecasting.\n",
    "- To develop a predictive model that can accurately forecast Nvidia's stock price for the next day using historical data.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The dataset for this lab is from the \"Huge Stock Market Dataset\" available on Kaggle. This dataset includes daily prices and volumes for all US stocks and ETFs, with a specific focus on Nvidia (NVDA). The dataset features include:\n",
    "\n",
    "- **Date**: The recorded data points.\n",
    "- **Open**: The price at which the stock first traded upon the opening of an exchange on a given trading day.\n",
    "- **High**: The highest price at which the stock traded during the trading day.\n",
    "- **Low**: The lowest price at which the stock traded during the trading day.\n",
    "- **Close**: The price of the stock at closing time.\n",
    "- **Volume**: The number of shares or contracts traded in a security or an entire market during a given period.\n",
    "- **OpenInt**: The total number of outstanding derivative contracts, like options or futures. [More details here](https://www.kaggle.com/datasets/borismarjanovic/price-volume-data-for-all-us-stocks-etfs/discussion/121096)\n",
    "\n",
    "### References\n",
    "\n",
    "- [Huge Stock Market Dataset](https://www.kaggle.com/datasets/borismarjanovic/price-volume-data-for-all-us-stocks-etfs) for the dataset used in this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {
    "id": "ad594fc8-4989-40f3-b124-4550fe7df386"
   },
   "source": [
    "## A. Checking and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QN9wm55dAwyz",
    "outputId": "abfb1c9b-0bc6-47de-ff66-fc7bb0e52b37"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "42a3eafd-cbcd-4c56-82cb-83a0bfa2399e",
    "outputId": "adb6958a-31b3-4e46-96ba-9069bb1a663c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/content/drive/MyDrive/lab4/nvda.us.txt')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "id": "97f3e5ca-600c-42f6-88d2-8e057ca2c612",
    "outputId": "f8b302f3-9580-46df-ccc2-28d339a80505"
   },
   "outputs": [],
   "source": [
    "plot = df.plot('Date', 'High', figsize=(15, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "id": "34241797-60f0-4818-a44b-f5379948d621",
    "outputId": "0f9dd676-57c2-4dc2-9842-d7289e778662"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {
    "id": "026585db-a6d8-4062-85de-e3a7eaebed72",
    "outputId": "4a48a79e-93b7-4c6e-a1e3-0c8806921b48"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "id": "69031e6d-0fb5-49d9-b723-a0d1fee08c3c",
    "outputId": "cc70bf8c-fa5a-486e-8a15-fc007275ab40"
   },
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {
    "id": "cb3090f8-2cfa-4f56-8aa5-cf954bb19932"
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "id": "38aadbee-d68f-4ae0-b842-b40800b0cac9",
    "outputId": "c961b79c-bd42-49fc-cc97-53a69e5e8843"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "051108c6-7011-4187-9e36-bd2944a019ca",
    "outputId": "9ee11904-01b2-48ec-eb44-93efeb6576a2"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "8ce7a0c5-76d6-4863-ba61-0544a220962a"
   },
   "source": [
    "#### Converting the DataFrame to a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "5735baad-2db8-4306-aa4c-7788d2b49621"
   },
   "outputs": [],
   "source": [
    "def create_sequences(input_data, output_data, window_size, step):\n",
    "    sequences = []\n",
    "    labels = []\n",
    "    for i in range(0, len(input_data) - window_size, step):\n",
    "        sequences.append(input_data[i:(i + window_size)])\n",
    "        labels.append(output_data[i + window_size])\n",
    "    return np.array(sequences), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29b8e189-7f39-435a-8038-39098b147325",
    "outputId": "b55eca3b-19a1-402a-c951-a928ba8a063d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select features\n",
    "features = df[['Open', 'High', 'Low', 'Close']]\n",
    "labels = df['High'].shift(-1)  # Next day's high price as label\n",
    "\n",
    "X, y = create_sequences(features, labels, window_size=10, step=15)\n",
    "\n",
    "print(f'Shape of data X: {X.shape}')\n",
    "print(f'Shape of data y: {y.shape}')\n",
    "\n",
    "# split the hold-out tests\n",
    "ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int) # 10% hold-out\n",
    "x_test = X[ind]\n",
    "y_test = y[ind]\n",
    "all_ind = np.arange(len(X))\n",
    "remains_ind = np.delete(all_ind, ind)\n",
    "\n",
    "X = X[remains_ind]\n",
    "y = y[remains_ind]\n",
    "\n",
    "# shuffle dataset\n",
    "ind = np.random.permutation(len(X))\n",
    "X = X[ind]\n",
    "y = y[ind]\n",
    "split_point = int(X.shape[0]*0.8)\n",
    "\n",
    "x_train = X[:split_point]\n",
    "y_train = y[:split_point]\n",
    "x_val = X[split_point:]\n",
    "y_val = y[split_point:]\n",
    "\n",
    "print(f'Shape of data x_train: {x_train.shape}')\n",
    "print(f'Shape of data y_train: {y_train.shape}')\n",
    "print(f'Shape of data x_val: {x_val.shape}')\n",
    "print(f'Shape of data y_val: {y_val.shape}')\n",
    "print(f'Shape of data x_test: {x_test.shape}')\n",
    "print(f'Shape of data y_test: {y_test.shape}')\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "x_train = torch.from_numpy(x_train).float()\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "x_val = torch.from_numpy(x_val).float()\n",
    "y_val = torch.from_numpy(y_val).float()\n",
    "\n",
    "x_test = torch.from_numpy(x_test).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "print(f'Number of samples in training and validation are {len(train_loader.dataset)} and {len(val_loader.dataset)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "id": "8ffc26b9-6044-41e9-93e2-7dc6250dbd27"
   },
   "source": [
    "## B. Defining Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "id": "77975746-a7a7-4676-9527-57674cd98c0f"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_layers, output_dim):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {
    "id": "cbb8b5b0-0ec0-406c-a42e-048aa00e05aa"
   },
   "source": [
    "## C. Training the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136,
     "referenced_widgets": [
      "1fed8b140f284e8ebc8591445aa9c8b2",
      "c9869ec3fe3441539037d1077fc8c9d8",
      "f779a5c3d646408c9a64079748f15a43",
      "93fe5e4fa03848ecb72c8e69f87e7c32",
      "b3f74ee7b31641aca73b9ff503252774",
      "9bf72d7a899943cd81befbd007ee45c7",
      "e743954e1d1b48568bb25bc5e7e7b2ed",
      "fd0f5dc228964e029e78bea65937d4eb",
      "e1f23f023cbb4153a37e81a08a8793f9",
      "af7f54f3d68b442d8dae643626dc765c",
      "d81ee583070540edbd32047d04a809a4"
     ]
    },
    "id": "f73a5c35-c15d-49bb-8a33-a7f017159499",
    "outputId": "f6fe7203-80f4-416e-b64a-3f51806bc6a1"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "epochs = 1\n",
    "\n",
    "model = LSTMModel(input_dim=4, hidden_dim=500, num_layers=2, output_dim=1).to(device)\n",
    "print(model)\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for features, labels in train_loader:\n",
    "        features = features.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(features).squeeze(-1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Learning rate update\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features).squeeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # Checkpoint\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train loss: {avg_train_loss:.4f}, Val loss: {avg_val_loss:.4f}, Best Val loss: {best_val_loss:.4f}')\n",
    "\n",
    "    # Store performance\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {
    "id": "a7984c6e-6652-4160-b572-07d48bc93a3f"
   },
   "source": [
    "#### Visualizing the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 464
    },
    "id": "5559d850-1fb5-4b04-b6ca-60c5b309f34e",
    "outputId": "c826098d-781c-4fff-8941-377dbbe5d9a5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {
    "id": "89c7e51b-8ab6-4aa2-877d-39b6daf55c20"
   },
   "source": [
    "## D. Evaluating Your Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {
    "id": "4bcf8580-42ee-4ee7-ad15-9f080cc57a33"
   },
   "outputs": [],
   "source": [
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "pred_value = []\n",
    "actual_value = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for features, labels in test_loader:\n",
    "        features = features.to(device)\n",
    "        outputs = model(features).squeeze(-1)\n",
    "        pred_value.append(outputs.cpu())\n",
    "        actual_value.append(labels)\n",
    "\n",
    "pred_value = torch.cat(pred_value)\n",
    "actual_value = torch.cat(actual_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 465
    },
    "id": "dde4e0a5-32be-4db3-95fb-4fad8926ce9b",
    "outputId": "1caac6e4-d93c-44f3-f6c3-2092e636cbbe"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(pred_value[:])\n",
    "plt.plot(actual_value[:])\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(['Pred', 'Actual'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {
    "id": "33920c41"
   },
   "source": [
    "## Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "061fee46"
   },
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {
    "id": "5f61c3f5"
   },
   "outputs": [],
   "source": [
    "def data_pipeline(window_size=10, step=15):\n",
    "    features = df[['Open', 'High', 'Low', 'Close']]\n",
    "    labels = df['High'].shift(-1)  # Next day's high price as label\n",
    "\n",
    "    X, y = create_sequences(features, labels, window_size=window_size, step=step)\n",
    "\n",
    "    # split the hold-out tests\n",
    "    ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int) # 10% hold-out\n",
    "    x_test = X[ind]\n",
    "    y_test = y[ind]\n",
    "    all_ind = np.arange(len(X))\n",
    "    remains_ind = np.delete(all_ind, ind)\n",
    "\n",
    "    X = X[remains_ind]\n",
    "    y = y[remains_ind]\n",
    "\n",
    "    # shuffle dataset\n",
    "    ind = np.random.permutation(len(X))\n",
    "    X = X[ind]\n",
    "    y = y[ind]\n",
    "    split_point = int(X.shape[0]*0.8)\n",
    "\n",
    "    x_train = X[:split_point]\n",
    "    y_train = y[:split_point]\n",
    "    x_val = X[split_point:]\n",
    "    y_val = y[split_point:]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    x_train = torch.from_numpy(x_train).float()\n",
    "    y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "    x_val = torch.from_numpy(x_val).float()\n",
    "    y_val = torch.from_numpy(y_val).float()\n",
    "\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    val_dataset = TensorDataset(x_val, y_val)\n",
    "    test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# model = LSTMModel(input_dim=4, hidden_dim=500, num_layers=2, output_dim=1).to(device)\n",
    "\n",
    "def Trainer(train_loader, val_loader, model, device, epochs=100):\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    lr_scheduler = CosineAnnealingLR(optimizer, T_max=epochs, eta_min=0)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Training\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        for features, labels in train_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features).squeeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Learning rate update\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_loader)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in val_loader:\n",
    "            features = features.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(features).squeeze(-1)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "\n",
    "    # Checkpoint\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    # Store performance\n",
    "    train_losses.append(avg_train_loss)\n",
    "    val_losses.append(avg_val_loss)\n",
    "\n",
    "    model.load_state_dict(torch.load('best_model.pth'))\n",
    "\n",
    "def Tester(test_loader, model, device):\n",
    "    model.eval()\n",
    "\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    pred_value = []\n",
    "    actual_value = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for features, labels in test_loader:\n",
    "            features = features.to(device)\n",
    "            outputs = model(features).squeeze(-1)\n",
    "            pred_value.append(outputs.cpu())\n",
    "            actual_value.append(labels)\n",
    "\n",
    "    pred_value = torch.cat(pred_value).cpu().detach().numpy()\n",
    "    actual_value = torch.cat(actual_value).cpu().detach().numpy()\n",
    "    return pred_value, actual_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "id": "54c46220"
   },
   "outputs": [],
   "source": [
    "def hw1(window_size, step):\n",
    "    train_loader, val_loader, test_loader = data_pipeline(window_size=window_size, step=step)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LSTMModel(input_dim=4, hidden_dim=500, num_layers=2, output_dim=1).to(device)\n",
    "    Trainer(train_loader, val_loader, model, device)\n",
    "    # pred_value, actual_value = Tester(test_loader, model, device)\n",
    "    return Tester(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 113,
     "referenced_widgets": [
      "1dca697354ca41e9aab2e722df1b5ff1",
      "b68a3ba5cc3c4925acc2df36d937c0e2",
      "4e9257f0e5374465a75c4d7e79937d97",
      "de6b054d3c4d4ddeab21e6f210c9bc3a",
      "1383951dda59420eaa063e9a3a57d75e",
      "452c2d0301014681885fa47d3db6488a",
      "cea7e242dbf2467280e9b06888bf2323",
      "66c79b049a834e7a8182f9b6fd440ebc",
      "d3315744f5854f779f3c92194d1b6afc",
      "c3d33718622045309ad4c6ee443af3c8",
      "ddfb19ef008d47e59daf776b535346b0",
      "9bf451341af74d43bb0786b41c2fa6e4",
      "1d94b14ee1d243adbd41c1ac994b1174",
      "c593d2cb275f480fa9061e02416f6113",
      "4a36e6e6a3684f118de8ed06fbd2fce6",
      "3e8c136a7c634dd3a3049f855eb36648",
      "21d9f6bfe7aa49dd88c8ffaf251ba1e7",
      "0dcdc281a00048d49b8890f85a6952c5",
      "cf3518c4d67645c082334316955033e9",
      "f41cf5dfcbdb4f3aaa55d211b4adfa79",
      "ad811f6e9f3b4656b7deee460d9f46d9",
      "783acd0c131648a395ab956ce7534039",
      "1fcfaab0d0c947a1bcd3013095dc594f",
      "c9f1136175f54dd7b202b860f543bbeb",
      "6feb772e4869446899983f22abea3e00",
      "a2cfbd67ceb64ea097dc5079886eb66d",
      "27751e661a75406eb807f5f982bfcb3e",
      "b43961026c0048c294eeb058a2d480c5",
      "3ae27de97491436e800bd083de8334ea",
      "5f6dda9abc9e4260b98636492b57e39f",
      "cd7090de161646619d2c8bcef63db489",
      "6920cae1da15463ea3784c354c7884c6",
      "1a0e848ac27a489bb90cafb75c5f9ea5"
     ]
    },
    "id": "25a6f655",
    "outputId": "9a7cdaef-b79a-4182-8776-6e1836c1cb23"
   },
   "outputs": [],
   "source": [
    "exp_params = [(5, 5), (5, 10), (10, 5)]\n",
    "mse = []\n",
    "pred = []\n",
    "for window_size, step in exp_params:\n",
    "    pred_value, actual_value = hw1(window_size, step)\n",
    "    pred.append(pred_value)\n",
    "    mse.append(np.mean((actual_value-pred_value)**2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78296bad",
    "outputId": "6d2cd376-c34a-4ad9-8508-15f58a55a9a5"
   },
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(f\"Window Size: {exp_params[i][0]}, Step: {exp_params[i][1]}; **MSE** = {mse[i]}\")\n",
    "# for i in range(3):\n",
    "#     plt.plot(pred[i][:], label=f\"{exp_params[i]}\")\n",
    "\n",
    "# plt.plot(actual_value[:], label=\"ground turth\")\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "2bfc9cdd248b4edb8683adec8d03a704",
      "2c41f93533464313a706c6d759c47bce",
      "81636cba9ace4dca8e066f1496e23ccf",
      "242aca0b563c4a0bb3b82ef0f1abadb2",
      "bbf5c17a193a45ccb6ae0cbc0262d0b9",
      "8e0e9d3b160444dc900973d744c3b831",
      "98f5d031dead41ac854fddb90f3d046b",
      "a382dab836ba44a2a28ac2ff2b4ba735",
      "d3ac05afc8bb481b8bf71b5cbfa10945",
      "25c8dd5b3fd44fcaa88b7222e0f6e64b",
      "70ca86de969a4ee5b2369b9b55866032"
     ]
    },
    "id": "4C6xuViRKC0B",
    "outputId": "8b3913bc-1984-4186-9361-e258e9492a91"
   },
   "outputs": [],
   "source": [
    "pred_value, actual_value = hw1(10, 15)\n",
    "mse.append(np.mean((actual_value-pred_value)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {
    "id": "D0U4pr12Jwqe"
   },
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "id": "393bb586"
   },
   "outputs": [],
   "source": [
    "def data_pipeline(window_size=10, step=15):\n",
    "    features = df[['Open', 'Close', 'High', 'Low']]\n",
    "    labels = df['High'].shift(-1)  # Next day's high price as label\n",
    "\n",
    "    X, y = create_sequences(features, labels, window_size=window_size, step=step)\n",
    "\n",
    "    # split the hold-out tests\n",
    "    ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int) # 10% hold-out\n",
    "    x_test = X[ind]\n",
    "    y_test = y[ind]\n",
    "    all_ind = np.arange(len(X))\n",
    "    remains_ind = np.delete(all_ind, ind)\n",
    "\n",
    "    X = X[remains_ind]\n",
    "    y = y[remains_ind]\n",
    "\n",
    "    # shuffle dataset\n",
    "    ind = np.random.permutation(len(X))\n",
    "    X = X[ind]\n",
    "    y = y[ind]\n",
    "    split_point = int(X.shape[0]*0.8)\n",
    "\n",
    "    x_train = X[:split_point]\n",
    "    y_train = y[:split_point]\n",
    "    x_val = X[split_point:]\n",
    "    y_val = y[split_point:]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    x_train = torch.from_numpy(x_train).float()\n",
    "    y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "    x_val = torch.from_numpy(x_val).float()\n",
    "    y_val = torch.from_numpy(y_val).float()\n",
    "\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    val_dataset = TensorDataset(x_val, y_val)\n",
    "    test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def hw2(window_size, step):\n",
    "    train_loader, val_loader, test_loader = data_pipeline(window_size=window_size, step=step)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LSTMModel(input_dim=4, hidden_dim=500, num_layers=2, output_dim=1).to(device)\n",
    "    Trainer(train_loader, val_loader, model, device)\n",
    "    # pred_value, actual_value = Tester(test_loader, model, device)\n",
    "    return Tester(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "referenced_widgets": [
      "687a5cc5eaf54b829d4d46fd49fcd5ef",
      "94075dbe50714f49911b0a5362a07892",
      "9d8089c2e506470d9c68b086036e0dcf",
      "d9bc00ad0c0b49aba3ba43546af92e18",
      "ea29600145724695b660caea2095e3a8",
      "685846660b0441f48514ac254bf680ae",
      "fabd35f56a8d464abb874daebbdbe54b",
      "df825e77965d45fa8373b2aac69f75bf",
      "2c216ce7e5344b2e9b0c0988837051b1",
      "08edf61cb3a34632876022ef1d7a8369",
      "42343eafafb848ab9f152c2b351824db",
      "6403aa07ba9a40d9830feaaf3621331d",
      "b0f8c374fb9048098e641939fee67dd4",
      "e84728e19f234ab4896582eddc760632",
      "80077f6a7355469ca47096373e1dbd28",
      "e3134177744f43809b0c706372ea0b4a",
      "63838136522546ef845da0d92418a60b",
      "ee7359f733c945b39a3dd67b1215fb40",
      "74626a6855d64b3a981c0ce6e347e8e2",
      "46f1cce69a6548069a4fdf491c4c1f12",
      "e40a238dad874bc4bda53fbc507160a8",
      "1d9cfbdf4f524a0b84d42e72a5dec928",
      "786c11d7f9b7482aabd035be439fb50c",
      "036c287341db4061984538f8e76d0d01",
      "13c5f525fa874350a69bfeccf653b4d7",
      "1426ae14728d4a8b9117aacff61b5868",
      "76c7d72c481d4415ac898a9d3bcfdec3",
      "87993633c408473b9057c1d753e7cbac",
      "2ae1cd5095d346ae88f0ec1e4cbce667",
      "75eeaeab326b47a3b6f207c56df19259",
      "ff80eb4e717c408b9a059a91aa9b83b8",
      "c0c4815005c24bb9ad1e3d5e06770403",
      "cc9e476696264dff8e92f15ec644d244"
     ]
    },
    "id": "7c100e10",
    "outputId": "f27f34fc-a2ce-4c84-f808-7f14ce184371"
   },
   "outputs": [],
   "source": [
    "exp_params = [(5, 5), (5, 3), (5, 2)]\n",
    "mse = []\n",
    "pred = []\n",
    "count = 0\n",
    "for window_size, step in exp_params:\n",
    "    pred_value, actual_value = hw2(window_size, step)\n",
    "    pred.append(pred_value)\n",
    "    mse.append(np.mean((actual_value-pred_value)**2))\n",
    "    print(f\"Window Size: {exp_params[count][0]}, Step: {exp_params[count][1]}; **MSE** = {mse[count]}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "referenced_widgets": [
      "ce35053895934b7e9fabcf128767fad8",
      "1a75075da9454cff9b6da5873d1669e8",
      "6207616e57c148f2b90104b419f9a0f5",
      "061e27e54a0f49d098641536cb0c04a7",
      "fb4b836214824a2b88697962c96eb316",
      "cbfc704728874d8ba9221331336c2d62",
      "a6565d46b3d34b48beaa61b6e6a17fdc",
      "385d7f9703234150862658db31795e40",
      "3d7765b78e794e81ab3f4c3d1e347702",
      "1bfbe68ab4d84710a07081bf9bd6dcf5",
      "f6f77792d9d24736bba30954b7dccf8f",
      "1dc21e3355a941e28b8a696c01b4fa76",
      "8f1e83827fc543fca3eb6d67f6b32c62",
      "d456af2dd2694040816cf61baf1e032b",
      "d76918a3d2784ca08f96cf4fc3dae6ae",
      "b7787db1f6c44d25bef235ccb2888c79",
      "23a95a28fa31431a94beb6ddb7c562aa",
      "6400a3d2e50948b881ba7815092e8765",
      "63db3192b5dc4844b0f324825698e337",
      "55bd8547e36d498da3eaed52260c484a",
      "d4a750a5fda64abdb1df59beb63916d5",
      "989b3110d1264afa9669a211fada7fab",
      "1454d125bede40b28eb8d862b9702130",
      "053eff6e9d234835a5d11b686f95a05a",
      "02d4571ffdd0477eaf16e128c96c5e01",
      "2a79dc36a3ac4847a59c78b83ba6241a",
      "4b19bd172d0e40f1bf0749c4cc06a62c",
      "b07ea893476842e38912c97e99509deb",
      "039e6fa7cc914e9ba3b0271dfba14b47",
      "836269812438496795657e7d1cc1b1f2",
      "af7755643ff943569438b762c6e4a87d",
      "a4328cebbb124e0f804aa5a462b9a791",
      "4076509d4c7043f7baf6da03bd2d75ea"
     ]
    },
    "id": "q8PSdzKdMC4a",
    "outputId": "7d211748-e459-4dc4-d457-93efd455a251"
   },
   "outputs": [],
   "source": [
    "exp_params = [(3, 5), (3, 3), (3, 2)]\n",
    "mse = []\n",
    "pred = []\n",
    "count = 0\n",
    "for window_size, step in exp_params:\n",
    "    pred_value, actual_value = hw2(window_size, step)\n",
    "    pred.append(pred_value)\n",
    "    mse.append(np.mean((actual_value-pred_value)**2))\n",
    "    print(f\"Window Size: {exp_params[count][0]}, Step: {exp_params[count][1]}; **MSE** = {mse[count]}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "id": "oIdMwVz1Mnam"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {
    "id": "-bTUNDMxNxuI"
   },
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {
    "id": "_nmfoY4WQH1l"
   },
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Date', 'OpenInt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {
    "id": "p1Au-bn-Nyek"
   },
   "outputs": [],
   "source": [
    "def data_pipeline(window_size=10, step=15):\n",
    "    normalized_df = (df - df.mean()) / df.std()\n",
    "    features = normalized_df[['Open', 'Close', 'High', 'Low']]\n",
    "    labels = normalized_df['High'].shift(-1)  # Next day's high price as label\n",
    "\n",
    "    X, y = create_sequences(features, labels, window_size=window_size, step=step)\n",
    "\n",
    "    # split the hold-out tests\n",
    "    ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int) # 10% hold-out\n",
    "    x_test = X[ind]\n",
    "    y_test = y[ind]\n",
    "    all_ind = np.arange(len(X))\n",
    "    remains_ind = np.delete(all_ind, ind)\n",
    "\n",
    "    X = X[remains_ind]\n",
    "    y = y[remains_ind]\n",
    "\n",
    "    # shuffle dataset\n",
    "    ind = np.random.permutation(len(X))\n",
    "    X = X[ind]\n",
    "    y = y[ind]\n",
    "    split_point = int(X.shape[0]*0.8)\n",
    "\n",
    "    x_train = X[:split_point]\n",
    "    y_train = y[:split_point]\n",
    "    x_val = X[split_point:]\n",
    "    y_val = y[split_point:]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    x_train = torch.from_numpy(x_train).float()\n",
    "    y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "    x_val = torch.from_numpy(x_val).float()\n",
    "    y_val = torch.from_numpy(y_val).float()\n",
    "\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    val_dataset = TensorDataset(x_val, y_val)\n",
    "    test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def hw3(window_size, step):\n",
    "    train_loader, val_loader, test_loader = data_pipeline(window_size=window_size, step=step)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LSTMModel(input_dim=4, hidden_dim=500, num_layers=2, output_dim=1).to(device)\n",
    "    Trainer(train_loader, val_loader, model, device)\n",
    "    # pred_value, actual_value = Tester(test_loader, model, device)\n",
    "    return Tester(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "referenced_widgets": [
      "52193a378cdc473d937e48bb48971bbe",
      "2032d2c09fda4ffa8670a785e34d0d26",
      "29f9b1f628dd46adbe5375fd386a50e0",
      "534aeb1d7d4b4c01abd33528fa3cb777",
      "74561176a187437196d39dad8429a306",
      "43435342756c4cf18878a17379f9ea5f",
      "d4e7ca790fc7445791be5e868e52b7e6",
      "7d6a4ef02bc244a1a4d24ba2299d2c89",
      "55eba10dd0194104b9d83d8b8787baf9",
      "123b17cc3a30444b8d506816b2bf256c",
      "7bd7262697474934bfcd5f0cb140312d",
      "a696cb035bc74914aaa16b4124ba38f9",
      "f6673006be0e4cadbc345555cfa5d3a5",
      "fda3e1e30fbe4f4f84150be4327c9b0c",
      "3dd0b69776c14d68bf9a5734776bcce4",
      "9202c7d380aa4b7aa755321e1ac701ad",
      "d9af84e5def14d46a6d5556b478c6b72",
      "400613abf2104eda9ec1a1f34b1f5bc8",
      "1af57afa08c048f49eb43ffeda3c7450",
      "acda2ede7d274e7eba0f6c10be6daa6d",
      "f37adfe8cd5947da83da3247ced560b3",
      "f606c9f209314aeea25cb7203042e510",
      "2d3fa4bed2c74d02b1d30f6e93d5cd4f",
      "e07892bccf2145a2aa97e26ddf2778d4",
      "d9181d90fe704cef88d76180f3a3326c",
      "5fd85e41d4274d719513cc3fdee6c41f",
      "6b6f8df08e784ebbaecffd4e3f45aed6",
      "84601b7031fb421fa59380f1f6a11dca",
      "d1cbef330e864d97a1a3e176d5a5a91b",
      "5ea13c65d6c043cd88b0b2d97fab2137",
      "e03bc52a85ff409a95d2e72a40635ea8",
      "7f1d7ea88c674c6788bc27e076fc5bf5",
      "a5633422ad834c2a84d1c587614fcffd"
     ]
    },
    "id": "3xsPgGpLPaSy",
    "outputId": "3ec289e9-66cb-4c89-a070-e92b33863fba"
   },
   "outputs": [],
   "source": [
    "exp_params = [(5, 3), (5, 2), (3, 2)]\n",
    "mse = []\n",
    "pred = []\n",
    "count = 0\n",
    "for window_size, step in exp_params:\n",
    "    pred_value, actual_value = hw3(window_size, step)\n",
    "    pred_value = pred_value * df.std()['High'] + df.mean()['High']\n",
    "    actual_value = actual_value * df.std()['High'] + df.mean()['High']\n",
    "    pred.append(pred_value)\n",
    "    mse.append(np.mean((actual_value-pred_value)**2))\n",
    "    print(f\"Window Size: {exp_params[count][0]}, Step: {exp_params[count][1]}; **MSE** = {mse[count]}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {
    "id": "BYGrSEz-QDv1"
   },
   "outputs": [],
   "source": [
    "def data_pipeline(window_size=10, step=15):\n",
    "    normalized_df = (df - df.mean()) / df.std()\n",
    "    features = normalized_df[['Open', 'Close', 'High', 'Low', 'Volume']]\n",
    "    labels = normalized_df['High'].shift(-1)  # Next day's high price as label\n",
    "\n",
    "    X, y = create_sequences(features, labels, window_size=window_size, step=step)\n",
    "\n",
    "    # split the hold-out tests\n",
    "    ind = np.linspace(0, len(X)-1, num=int(len(X)*0.1), dtype=int) # 10% hold-out\n",
    "    x_test = X[ind]\n",
    "    y_test = y[ind]\n",
    "    all_ind = np.arange(len(X))\n",
    "    remains_ind = np.delete(all_ind, ind)\n",
    "\n",
    "    X = X[remains_ind]\n",
    "    y = y[remains_ind]\n",
    "\n",
    "    # shuffle dataset\n",
    "    ind = np.random.permutation(len(X))\n",
    "    X = X[ind]\n",
    "    y = y[ind]\n",
    "    split_point = int(X.shape[0]*0.8)\n",
    "\n",
    "    x_train = X[:split_point]\n",
    "    y_train = y[:split_point]\n",
    "    x_val = X[split_point:]\n",
    "    y_val = y[split_point:]\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    x_train = torch.from_numpy(x_train).float()\n",
    "    y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "    x_val = torch.from_numpy(x_val).float()\n",
    "    y_val = torch.from_numpy(y_val).float()\n",
    "\n",
    "    x_test = torch.from_numpy(x_test).float()\n",
    "    y_test = torch.from_numpy(y_test).float()\n",
    "\n",
    "    batch_size = 32\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = TensorDataset(x_train, y_train)\n",
    "    val_dataset = TensorDataset(x_val, y_val)\n",
    "    test_dataset = TensorDataset(x_test, y_test)\n",
    "\n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def hw3_2(window_size, step):\n",
    "    train_loader, val_loader, test_loader = data_pipeline(window_size=window_size, step=step)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = LSTMModel(input_dim=5, hidden_dim=500, num_layers=2, output_dim=1).to(device)\n",
    "    Trainer(train_loader, val_loader, model, device)\n",
    "    # pred_value, actual_value = Tester(test_loader, model, device)\n",
    "    return Tester(test_loader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 165,
     "referenced_widgets": [
      "1de26a6f226c4ea88c66961d88a4f4e9",
      "b27a330c1de846b69c65b184177ac805",
      "98282e15ee5e47cd895c9eb93575ee02",
      "1e129e88cd844a4291fc891977614502",
      "5412a5482ac24e33a9fd3df643683645",
      "0a5b44350382462ba4c52e7b0ff0206f",
      "54b40de246904291a3fa5bfd1470df3b",
      "5b8b4e96ec7246f7802b503888337324",
      "fc27e5bd4cde4173ab0bbd15d2fb1f8c",
      "c7446989f58f4ca7ae3af14d1c1aa788",
      "61dcb33c192d4c159d922d8b4bd8c479",
      "768b68020a434d8c805ecbb1ac3eff7c",
      "d3ac243ba18e48c0afd190f08b0f0b27",
      "3a14cc6f26a649f383f81b1fd0f20073",
      "704adead72c64088861be32bf53e7927",
      "aeaaa78e9c9f4597b4a0db81323279da",
      "86c11608733d4662b5ade8d768f97d96",
      "7cecf97a6a794c5da3fa2c8ffe16007d",
      "5a98ee0799b041b6963e1c31a0c04027",
      "569f6c0f421b4a7f8d1122b2917ee5fd",
      "c64e37c3067144a8b2b880c79bcbe3f1",
      "c45b60ea0a544382a9d673ff2bcbc168",
      "68cbc9405dd147d385f81c199e784985",
      "bcba190551bd4b0d8f7289dd688db086",
      "20e01cf2d6c04dbf83b4b46ee856f048",
      "6db0037f27654efabda4acb1d50ad491",
      "026c5b4fc8a840ab88de4e4e35e710fb",
      "3c889b157d0e40a7a61a35db3ae86128",
      "44ef4180045b48d4b5a2bc0a9b5eac16",
      "3aec1fe3b0ad4b28be276fd265e3226b",
      "abb64c7f27864139b82fb6b83ff96aa5",
      "8392fe3ad4e342bdb865e9fc1fe5b8ce",
      "0123e59f7baf46eb837b1541884cd59f"
     ]
    },
    "id": "z8fIKU3KTtry",
    "outputId": "0b1cc33d-18f1-4ed9-9fc4-de046ab2d4aa"
   },
   "outputs": [],
   "source": [
    "exp_params = [(5, 3), (5, 2), (3, 2)]\n",
    "mse = []\n",
    "pred = []\n",
    "count = 0\n",
    "for window_size, step in exp_params:\n",
    "    pred_value, actual_value = hw3_2(window_size, step)\n",
    "    pred_value = pred_value * df.std()['High'] + df.mean()['High']\n",
    "    actual_value = actual_value * df.std()['High'] + df.mean()['High']\n",
    "    pred.append(pred_value)\n",
    "    mse.append(np.mean((actual_value-pred_value)**2))\n",
    "    print(f\"Window Size: {exp_params[count][0]}, Step: {exp_params[count][1]}; **MSE** = {mse[count]}\")\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42",
   "metadata": {
    "id": "odLD0ZgaTt9k"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
